% a line in tab:grapple
% these numbers come from tables 2 and 3 in the grapple paper from EuroSys '19.
% for TPs and FPs, I added together the IO and Socket columns of table 2.
%\newcommand{\grappletablerow}[4]{\textbf{\smaller{#1}} & #2 & #3 & #4}
\newcommand{\grappletableproject}[1]{\textbf{\smaller{#1}}}
% "ac" = "acronym character"
\newcommand{\ac}[1]{\textbf{\underline{#1}}}

\begin{table}
  \caption{Comparison of resource leak checking tools:  \ac{Ecl}ipse,
    \ac{Gr}apple, and the \ac{R}esource \ac{L}eak \ac{C}hecker.
    As is standard,
    recall is the ratio of reported leaks to all leaks present in the code,
    and precision is the ratio of true positive warnings to all tool warnings.
    Different tools were run on different versions of the case study
    programs.
    The number of leaks and the
    recall are computed over the code that is common to all versions of the
    programs, so recall is directly comparable within rows.
    Precision is computed over the code version analyzed by each tool, so it may
    not be directly comparable within rows.
    % for example, different versions of ZooKeeper might
    % contain different mixes of code patterns that lead to false positive warnings.
    Eclipse reports no high-confidence warnings for JDK types in HBase.\looseness=-1
    %% , leading
    %% to the - in the precision column.  The ``Total'' row was
    %% computed by summing true and false positive counts across benchmarks.
}
  \label{tab:tool-comparison}
  \posttablecaption
  \begin{tabular}{l|rccc|ccc}
                 &  & \multicolumn{3}{c|}{\textbf{Recall}} & \multicolumn{3}{c}{\textbf{Precision}*} \\
                         Project &      leaks & Ecl  & Gr  & RLC  &   Ecl   & Gr   & RLC \\
    \hline
    \grappletableproject{ZooKeeper}      & 6  & 17\% & 17\% & 100\% & 33\% & 67\% & 21\% \\
    \grappletableproject{HDFS}           & 7  & 14\% & 0\%  & 100\% & 20\% & 71\% & 32\% \\
    \grappletableproject{HBase}          & 2  & 0\%  & 0\%  & 100\% &  -   & 35\% & 19\% \\
    \hline
    \grappletableproject{\textbf{Total}} & 15 & 13\% & 7\%  & 100\% & 25\% & 50\% & 26\% \\
  \end{tabular}
\end{table}

%%%%%
% What follows is the raw numbers that we used to compute the %s in the table above.
%%%%%

%%% Eclipse %%%

% On ZooKeeper, Eclipse produces 3 warnings in high-confidence mode: 1 TP and 2 FPs (precision: 1/3 = 33%).
% The one TP is in TraceFormatter.java, which IS one of the six leaks present in the version analyzed by Grapple (recall: 1/6 = 17%).

% On HDFS, Eclipse produces 5 warnings in high-confidence mode: 1 TP and 4 FPs (precision 1/5 = 20%).
% The one TP is in EditLogFileOutputStream.java, which IS one of the seven leaks present in the version analyzed by Grapple (recall: 1/7 = 14%).

% On Hbase, Eclipse produces no warnings in high-confidence mode about JDK types (it does produce some about custom types, but we don't count those).
% Therefore, the recall is 0/2 = 0%, and precision is 0/0 = NaN. I used a - in the table to represent that.

% In total, Eclipse issued 8 warnings on the benchmarks. Of these, 2 were TPs in the set of 15 we analyzed, for an overall recall of 2/15 = 13%.
% Of the 8 warnings Eclipse issued, 1 + 1 + 0 = 2 were TPs and 2 + 4 + 0 = 6 were FPs, for a total precision of 2/8 = 25%.

%%% Grapple %%%

% On ZooKeeper, there are 6 TPs found by the RLC that are present in the version of ZooKeeper that Grapple analyzed.
% Of these, Grapple found 1, for a recall of 1/6 = 17%.
% The Grapple paper claimed to find 6 TPs and 0 FPs in the version of Zookeeper they analyzed. Our re-examination of the warnings
% discovered that 2 of these were actually false positives (StringWriter doesn't hold a resource). Thus, the precision of Grapple
% on Zookeeper is 4/6 = 67%.

% On HDFS, there are 7 TPs found by the RLC that are present in the version of HDFS that Grapple analyzed.
% Of these, Grapple found 0, for a recall of 0/7 = 0%.
% The Grapple paper claimed to find 5 TPs and 2 FPs in the version of HDFS that they analyzed. We did not discover any problems with
% their classification, so their precision is 5/7 = 71%.

% On HBase, there are 2 TPs found by RLC that were present in the version analyzed by Grapple.
% Of these, Grapple found 0, for a recall of 0/2 = 0%.
% The Grapple paper claimed to find 15 TPs and 2 FPs in the version of HBase they analyzed. Of these, we believe that 9 were not actually
% true positives. (Martin thinks these are also caused by the StringWriter thing, but some might not be. Narges did this analysis.)
% Treating those 9 as FPs, we arrive at a total of 6 TPs and 11 FPs. Grapple's precision is therefore 6/17 = 35%.

% In total, Grapple found 1 of the 15 leaks that were present in the version they analyzed, for a recall of 1/15 = 7%.
% On their own version, accounting for the mistakes in classification, Grapple found a total of 4 + 5 + 6 = 15 TPs
% and 2 + 2 + 11 = 15 FPs, for a precision of 15/30 = 50%.

%%% RLC %%%

% The RLC numbers are taken from table 1. For recall, RLC was used to construct the ground truth, so recall is by construction 100%.
% (This is not a problem, because RLC is sound: there are no other resource leaks present in both analyzed versions of the programs.)
% For precision, RLC's precision on each benchmark in the entry in the ``resource leaks'' column of table 1 over the sum of the ``resource leaks''
% and ``false positives'' columns. These numbers are:
% ZK: 13 / (13 + 48 = 61) = 21%.
% HDFS/hadoop: 23 / (23 + 49 = 72) = 32%.
% HBase: 5 / (5 + 22 = 27) = 19%.
% Total: (13 + 23 + 5) / (61 + 72 + 27) = 41 / 160 = 26%.

% LocalWords:  HDFS rcccr TPs FPs ZooKeeper HBase Ecl ipse esource eak RLC
% LocalWords:  hecker Grapple
