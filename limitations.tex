\section{Limitations and threats to validity}
\label{sec:threats}

Like any tool that analyzes source code, \tool only
gives guarantees for code that it checks: the guarantee
excludes native code, the implementation of unchecked libraries (such as the JDK),
and code generated dynamically or by other annotation processors
such as Lombok.
%% MK: the sentence says that we can't guarantee that code generated by annotation
%% processors is checked, which is true, because they can misbehave in the way
%% that Lombok does. Most annotation processors don't, but the point is that
%% they can, so we can't promise that our analysis will be applied.
%% \todo{nit: is it annotation processors in general that cause an
%% issue, or Lombok because of the insane things it does?  I think for a typical
%% annotation processor doing code generation we shouldn't have problems?}
Though
the Checker Framework can handle 
reflection soundly~\cite{BarrosJMVDdAE2015}, by default (and in our case studies)
\tool compromises this guarantee
by assuming that objects returned by reflective invocations
do not carry must-call obligations (but this behavior can
be disabled).
% Like any sound static analysis, \Tool does
% issue some false positives; these must be suppressed by
% the programmer and the correctness of the relevant code
% must be proved using another method.
Within the bounds
of a user-written warning suppression, \tool assumes that 1)
any errors issued can be ignored, and 2) all annotations
written by the programmer are correct.

\todo{Someone please take a look a this para before we submit} The soundness of
\tool is with respect to specifications of which types of objects have a
\<@MustCall> obligation that must be satisfied.  We wrote such specifications
for the Java standard library, focusing on IO-related code in the \<java.io> and
\<java.nio> packages.  Any missing specifications of \<@MustCall> obligations
could lead \tool to miss resource leaks.

The results of our experiments may not generalize, compromising the
external validity of the experimental results.
% In particular, our subject programs are
% heavily-used, heavily-tested, and contain a high-density of resource
% usage---so, in a sense, they represent a worst-case scenario for
% \Tool.  Nevertheless,
\Tool may produce more false positives, require
more annotations, or be more difficult to use if applied to other
programs.  It would be both easier and more useful to use \tool from
the inception of a project, rather than applying it after the code had
already be written, as we did in our case studies: code could be
annotated as it was written.  This would ensure that the annotations match
the intent of the programmers and would guide the programmers to a better design.
The need for annotations at all could be viewed as a limitation of our approach;
however, the annotations serve as concise documentation of
properties relevant to resource leaks (and unlike traditional, natural-language
documentation, machine-checked annotations cannot become out-of-date).

Like any practical system, it is possible that there might
be defects in the implementation of \tool or in the design of
its analyses. We have mitigated this threat with code review and an extensive
test suite for \tool:
% to collect these numbers, run these commands and sum the results:
% cd object-construction-checker/tests
% scc mustcall socket nolightweightownership mustcall-onlyjdk noresourcealias noaccumulationframes
% cd ../../must-call-checker/tests
% scc
119 test classes containing 3,776 lines of non-comment, non-blank code.
\todo{Update the numbers in the previous paragraph immediately before submission.}
This test suite is publicly available and distributed with \tool.

% LocalWords:  checkable
