\section{Limitations and threats to validity}
\label{sec:threats}

Like any tool that analyzes source code, \Tool only
gives guarantees for code that it checks: the guarantee
excludes native code, the implementation of unchecked libraries (such as the JDK),
and code generated dynamically or by other annotation processors
such as Lombok.
%% MK: the sentence says that we can't guarantee that code generated by annotation
%% processors is checked, which is true, because they can misbehave in the way
%% that Lombok does. Most annotation processors don't, but the point is that
%% they can, so we can't promise that our analysis will be applied.
%% \todo{nit: is it annotation processors in general that cause an
%% issue, or Lombok because of the insane things it does?  I think for a typical
%% annotation processor doing code generation we shouldn't have problems?}
Though
the Checker Framework can handle 
reflection soundly~\cite{BarrosJMVDdAE2015}, by default (and in our case studies)
\Tool compromises this guarantee
by assuming that objects returned by reflective invocations
do not carry must-call obligations (but this behavior can
be disabled).
% Like any sound static analysis, \Tool does
% issue some false positives; these must be suppressed by
% the programmer and the correctness of the relevant code
% must be proved using another method.
Within the bounds
of a user-written warning suppression, \Tool assumes that 1)
any errors issued can be ignored, and 2) all annotations
written by the programmer are correct.

The results of our experiments may not generalize, compromising the
external validity of the experimental results.
% In particular, our subject programs are
% heavily-used, heavily-tested, and contain a high-density of resource
% usage---so, in a sense, they represent a worst-case scenario for
% \Tool.  Nevertheless,
\Tool may produce more false positives, require
more annotations, or be more difficult to use if applied to other
programs.  It would be both easier and more useful to use \Tool from
the inception of a project, rather than applying it after the code had
already be written, as we did in our case studies: code could be
annotated as it was written.  This would ensure that the annotations match
the intent of the programmers and would guide the programmers to a better design.

Like any practical system, it is possible that there might
be bugs in the implementation of \Tool, or in the design of
its analyses. We have mitigated this threat with code review and an extensive
test suite for \Tool:
% to collect these numbers, run scc in the tests directory of
% object-construction-checker and must-call-checker subprojects of
% fse-main-307/plumber and sum the results
110 test classes containing 3,458 lines of non-comment, non-blank code.
\todo{Update the numbers in the previous paragraph immediately before submission.}
This test suite is publicly available and distributed with \Tool.
